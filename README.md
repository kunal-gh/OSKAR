<div align="center">

<img src="https://img.shields.io/badge/Status-Production_Ready-success?style=for-the-badge"/>
<img src="https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white"/>
<img src="https://img.shields.io/badge/FastAPI-0.109+-009688?style=for-the-badge&logo=fastapi&logoColor=white"/>
<img src="https://img.shields.io/badge/PyTorch_Geometric-GNN-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white"/>
<img src="https://img.shields.io/badge/Transformers-HuggingFace-FFD21E?style=for-the-badge&logo=huggingface&logoColor=black"/>
<img src="https://img.shields.io/badge/FAISS-Vector_Search-181717?style=for-the-badge&logo=meta&logoColor=white"/>
<img src="https://img.shields.io/badge/Neo4j-Graph_RAG-4581C3?style=for-the-badge&logo=neo4j&logoColor=white"/>
<img src="https://img.shields.io/badge/Kubernetes-K8s-326CE5?style=for-the-badge&logo=kubernetes&logoColor=white"/>

# ğŸ›¡ï¸ OSKAR
### **Online Safety & Knowledge Authenticity Resolver**

*An advanced, uncertainty-aware ML moderation engine combining Transformer-based NLP, Graph-RAG Verification, and Graph Neural Networks (GNN) to detect toxicity, misinformation, and coordinated bot swarms at scale.*

[Key Features](#-key-innovations) â€¢ [ML Architecture](#-machine-learning-architecture) â€¢ [Graph-RAG](#-graph-rag--evidence-retrieval) â€¢ [GNN Swarm Detection](#-gnn-bot-swarm-detection) â€¢ [API Contracts](#-api-data-contracts)

</div>

---

## ğŸš€ The Engineering Challenge

Modern content moderation fails because it treats posts as isolated strings of text evaluated by deterministic rules or overconfident classifiers. This leads to **three major failure states**:
1. **Context Blindness**: An algorithm flags sarcasm as hate speech, or approves dangerous misinformation.
2. **Coordinated Bot Swarms**: Threat actors use distributed networks of accounts to trick simple filters.
3. **Black Box Overconfidence**: Neural networks output 99% confidence on out-of-distribution data.

**OSKAR** solves this by treating moderation as a **Bayesian Information Retrieval and Graph Classification problem**. It doesn't just evaluate text; it evaluates the semantic truth of claims against a knowledge graph, analyzes the network topology of the user, and applies entropy-based temperature scaling to guarantee the system *knows what it doesn't know*.

---

## ğŸ§  Machine Learning Architecture

The OSKAR pipeline is a high-throughput DAG (Directed Acyclic Graph) of specialized micro-models, aggressively optimized for `< 250ms` p95 latency.

```mermaid
graph TD
    classDef user fill:#2d3748,stroke:#4a5568,color:#fff
    classDef nlp fill:#3182ce,stroke:#2b6cb0,color:#fff
    classDef graph fill:#38a169,stroke:#2f855a,color:#fff
    classDef core fill:#805ad5,stroke:#6b46c1,color:#fff
    classDef db fill:#dd6b20,stroke:#c05621,color:#fff

    User[Client Request: Text + Local Subgraph]:::user --> API[FastAPI Gateway]:::core

    API --> Hate[RoBERTa Hate Classifier]:::nlp
    API --> Claim[DeBERTa Zero-Shot Claim Extractor]:::nlp
    API --> GNN[GraphSAGE Swarm Detector]:::graph

    Claim -- If Verifiable --> FAISS[(FAISS Vector Index)]:::db
    Claim -- If Verifiable --> Neo4j[(Neo4j Knowledge Graph)]:::db

    FAISS --> RAG[Graph-RAG Verification]:::graph
    Neo4j --> RAG

    Hate --> Fusion[Risk Fusion Engine]:::core
    RAG --> Fusion
    GNN --> Fusion

    Trust[(PostgreSQL Bayesian Trust Store)]:::db --> Fusion
    
    Fusion --> Cog[Cognitive Engine: Entropy Router]:::core
    
    Cog -- Entropy < 0.6 --> Auto[Auto Action]:::user
    Cog -- 0.6 < Entropy < 0.8 --> Warn[Soft Warning]:::user
    Cog -- Entropy > 0.8 --> Human[Human Review]:::user
```

### 1. NLP Deep Sequence Models
- **Toxicity Classification**: Fine-tuned `cardiffnlp/twitter-roberta-base-hate`. Optimized for handling internet-native slang, AAVE, and short-form conversational text.
- **Verifiable Claim Extraction**: `MoritzLaurer/deberta-v3-large-zeroshot-v2` (Masked LM). Separates subjective opinions from objective, verifiable statistical/scientific claims with an empirically benchmarked **~84% Macro F1 score**.

---

## ğŸ•¸ï¸ Graph-RAG & Evidence Retrieval

Instead of hallucinating truth, OSKAR verifies claims through a two-stage hybrid Graph Retrieval-Augmented Generation (Graph-RAG) architecture.

1. **Dense Vector Retrieval (FAISS)**: 
   - Uses `sentence-transformers/all-mpnet-base-v2` (768-dim embeddings) to map extracted claims to a pre-computed FAISS index of verified encyclopedia passages and scientific consensus texts.
   - Sub-millisecond $L2$ distance search returns top-$k$ contextual evidence.

2. **Knowledge Graph Traversal (Neo4j)**:
   - Entities are extracted and queried against a Neo4j instance containing structured truth triples `(Subject)-[RELATION]->(Object)`.
   - **Intersection Algorithm**: If the semantic vector cosine similarity is high, *and* a 2-hop graph path connects the claim's entities in the KG, confidence is boosted by a non-linear scaling factor.

---

## ğŸ¦  GNN Bot Swarm Detection

Standard moderation ignores *who* is posting. OSKAR v0.3 introduces **Coordinated Inauthentic Behavior (CIB)** detection using PyTorch Geometric.

- **Algorithm**: `GraphSAGE` (Sample and Aggregate)
- **Features**: Nodes are embedded with `[account_age, post_frequency, toxicity_variance]`.
- **Mechanism**: By analyzing the local edge topology (who interacts with whom), GraphSAGE identifies tightly clustered nodes exhibiting identical behavior varianceâ€”the mathematical signature of a bot farm.
- **Risk Multiplier**: A high `swarm_probability` acts as a multiplicative amplifier in the Risk Fusion engine, instantly escalating mundane text to Human Review if posted by a swarm.

---

## ğŸ§® Cognitive Engine & Risk Fusion

The Risk Fusion engine prevents black-box overconfidence using **Temperature Scaling** and **Information Entropy**.

$$ \text{Calibrated_Probabilities} = \text{Softmax}\left(\frac{\text{Logits}}{T}\right) $$
$$ \text{Entropy } (H) = -\sum_{i} P(x_i) \log_2 P(x_i) $$

1. **Monte Carlo Simulations**: Calculates risk confidence intervals rather than absolute numbers.
2. **Bayesian Trust Priors**: Fetches the user's longitudinal trust score from PostgreSQL. A strong prior of factual posts degrades the impact of anomalous weak flags.
3. **Entropy Routing**: If Information Entropy $H > 0.8$, the system admits it does not know the answer and routes to the `human_review` queue.

---

## ğŸ— K8s & Cloud Infrastructure
OSKAR is production-designed. It ships with `docker-compose` for local MLOps and Helm charts for Kubernetes scaling.

```mermaid
architecture-beta
    group api(cloud)[FastAPI Serving Layer]
    group ml(cloud)[ML Inference Workers]
    group db(cloud)[State & Storage]

    service gw(internet)[Gateway]
    service server(server)[Uvicorn Workers] in api
    service redis(database)[Redis Semantic Cache] in db
    
    service gpu_hate(server)[RoBERTa Pod (GPU)] in ml
    service gpu_gnn(server)[PyTorch GNN Pod] in ml
    
    service pg(database)[PostgreSQL] in db
    service neo4j(database)[Neo4j Graph] in db
    service faiss(database)[FAISS In-Memory] in ml

    gw:R --> L:server
    server:R --> L:redis
    server:R --> L:pg
    
    server:B --> T:gpu_hate
    server:B --> T:gpu_gnn
    server:B --> T:faiss
    faiss:R --> L:neo4j
```

---

## ğŸ“‚ Project Architecture Showcase

To maintain enterprise-grade separation of concerns, OSKAR follows a clean Domain-Driven `src/` modular layout:

```text
OSKAR/
â”œâ”€â”€ MVP/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/                 # FastAPI routes, Pydantic contracts, Auth
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”‚   â”œâ”€â”€ canary_router.py
â”‚   â”‚   â”‚   â””â”€â”€ compliance_manager.py
â”‚   â”‚   â”œâ”€â”€ models/              # Transformer & GNN Inference pipelines
â”‚   â”‚   â”‚   â”œâ”€â”€ hate_classifier.py
â”‚   â”‚   â”‚   â”œâ”€â”€ claim_classifier.py
â”‚   â”‚   â”‚   â”œâ”€â”€ drift_detector.py
â”‚   â”‚   â”‚   â””â”€â”€ ocr_analyzer.py
â”‚   â”‚   â”œâ”€â”€ core/                # Business Logic, Entropy, & Risk Math
â”‚   â”‚   â”‚   â”œâ”€â”€ trust_engine.py
â”‚   â”‚   â”‚   â”œâ”€â”€ cognitive_engine.py
â”‚   â”‚   â”‚   â””â”€â”€ risk_fusion.py
â”‚   â”‚   â””â”€â”€ infra/               # Databases, Data Ingestion, FAISS, Neo4j
â”‚   â”‚       â”œâ”€â”€ neo4j_knowledge_graph.py
â”‚   â”‚       â”œâ”€â”€ redis_cache.py
â”‚   â”‚       â””â”€â”€ stream_ingester.py
â”‚   â”œâ”€â”€ tests/                   # 100% Core coverage Pytest suite
â”‚   â”œâ”€â”€ k8s/                     # Kubernetes deployment configurations
â”‚   â”œâ”€â”€ Dockerfile               # Multi-stage optimized Docker build
â”‚   â””â”€â”€ docker-compose.yml       # Local integration cluster
â””â”€â”€ Documentation/               # Architecture logic & whitepapers
```

---

## âš¡ Performance Budget

Optimized for high-throughput streaming environments.

| Subsystem | Target Latency | Actual (CPU) | Actual (A100 GPU) |
|---|---|---|---|
| Hate Classification (RoBERTa) | $\leq 120ms$ | ~90ms | **~12ms** |
| Claim Extraction (DeBERTa-v3) | $\leq 150ms$ | ~125ms | **~18ms** |
| FAISS L2 Search (1M Vectors) | $\leq 50ms$ | ~3ms | **~1ms** |
| GraphSAGE Swarm Inference | $\leq 20ms$ | ~5ms | **~1ms** |
| **Total Pipeline $p95$** | $\leq 350ms$ | ~223ms | **~32ms** |

---

## ğŸ“¡ API Data Contracts

OSKAR communicates via strict, versioned JSON responses.

```json
POST /api/v1/analyze

{
  "risk_score": 0.91,
  "confidence_interval": [0.85, 0.96],
  "entropy": 0.42,
  "route": "human_review",
  "ml_components": {
    "nlp_hate": {
      "label": "non_hate",
      "model_confidence": 0.96,
      "calibrated_uncertainty": 0.17
    },
    "zero_shot_claims": {
      "is_verifiable": true,
      "claim_classification": "scientific"
    },
    "graph_rag_verification": {
      "verdict": "refuted",
      "evidence_vector_dist": 0.14,
      "graph_triples": [
        {"subject": "CDC", "relation": "STATES", "object": "Vaccines safe"}
      ]
    },
    "gnn_swarm": {
      "cib_probability": 0.87,
      "topology_variance": 0.02
    }
  },
  "bayesian_trust_prior": 0.50
}
```

---

## ğŸ› ï¸ Quick Start

**Prerequisites:** Python 3.11, Docker

1. **Clone & Install**
```bash
git clone https://github.com/kunal-gh/OSKAR.git
cd OSKAR/MVP
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

2. **Boot the Backend Graph & Datastores**
```bash
docker compose up -d redis postgres neo4j
```

3. **Run the OSKAR Inference Server**
```bash
python src/api/main.py
```

4. **Run the Test Suite**
```bash
pytest tests/ -v
```

---

<div align="center">

**Engineered by Kunal**  
*Building scalable ML systems that prioritize precision, architecture, and truth.*

</div>
