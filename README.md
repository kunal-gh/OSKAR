<div align="center">

# ğŸ›¡ï¸ OSKAR: Online Safety & Knowledge Authenticity Resolver
### **The Next Generation of AI Content Moderation & Information Integrity**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-009688?style=for-the-badge&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.2+-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org/)
[![Neo4j](https://img.shields.io/badge/Neo4j-Graph--RAG-4581C3?style=for-the-badge&logo=neo4j&logoColor=white)](https://neo4j.com/)
[![Docker](https://img.shields.io/badge/Docker-Production--Ready-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)

---

> **"Truth is not a binary. It's an architecture."**
> 
> OSKAR is a production-grade inference engine that moves beyond simple keyword filters. It combines **Transformers**, **Vector Space Models (FAISS)**, **Knowledge Graphs (Neo4j)**, and **Graph Neural Networks (GNNs)** into an uncertainty-aware framework.

[Key Innovations](#-key-innovations) â€¢ [System Architecture](#-modular-system-architecture) â€¢ [Module Deep Dive](#-machine-learning-deep-dive) â€¢ [API & Metrics](#-api-specification)

</div>

---

## ğŸŒŸ Key Innovations

What makes OSKAR a "Resume-Killer" project is its departure from deterministic moderation:
1.  **Entropy-Based Uncertainty**: The system *admits* when it is confused, routing ambiguous content to human experts rather than making a bad guess.
2.  **Graph-RAG Verification**: Instead of hallucinating, OSKAR verifies claims through a hybrid search across Euclidean vector space and relational Knowledge Graphs.
3.  **Bayesian Trust Scoring**: Tracks user reliability over time using longitudinal statistical priors.
4.  **GNN Swarm Detection**: Identifies coordinated bot farms by analyzing the social graph topology via **GraphSAGE**.

---

## ğŸ›ï¸ Modular System Architecture

### **High-Level Data Flow Orchestration**

```mermaid
graph TD
    classDef input_style fill:#f9f9f9,stroke:#333,stroke-width:2px;
    classDef nlp_style fill:#e1f5fe,stroke:#01579b,color:#01579b;
    classDef data_style fill:#f1f8e9,stroke:#33691e,color:#33691e;
    classDef core_style fill:#805ad5,stroke:#6b46c1,color:#fff;
    classDef exit_style fill:#fff3e0,stroke:#e65100,color:#e65100;

    START[Post/Analyze Request]:::input_style --> INP{Orchestrator}
    
    subgraph "Inference Pipeline"
        INP --> HATE[RoBERTa Hate]:::nlp_style
        INP --> CLAIM[DeBERTa-v3 Claims]:::nlp_style
        INP --> GNN[GraphSAGE Topology]:::data_style
    end

    subgraph "Verification Layer (Graph-RAG)"
        CLAIM --> EMB[SBERT Embeddings]
        EMB --> FAISS[(FAISS Vector Index)]:::data_style
        FAISS --> N4J[(Neo4j Fact triples)]:::data_style
    end

    subgraph "Decision Fusion"
        HATE --> FUSION[Risk Engine]:::core_style
        N4J --> FUSION
        GNN --> FUSION
        FUSION --> CAL[Calibration & Entropy]:::core_style
    end

    CAL --> VERDICT[Final Verdict]:::exit_style
```

---

## ğŸ”¬ Machine Learning Deep Dive

### Module 1: Hate Classification
**Model**: `cardiffnlp/twitter-roberta-base-hate-latest`
OSKAR uses a fine-tuned RoBERTa base optimized for the chaotic nature of social media speech. Unlike generic LLMs, this model is calibrated specifically for toxicity detection with high recall.

### Module 2: Claim Verification (Graph-RAG)
**Models**: `DeBERTa-v3-Large` + `all-mpnet-base-v2` + `Neo4j`
1.  **Extraction**: DeBERTa identifies objective claims.
2.  **Retrieval**: FAISS matches claims to a 5,000-document knowledge base.
3.  **Relational Check**: Neo4j verifies entity relationships (e.g., `(Subject)-[PROVEN_BY]->(Fact)`).

### Module 3: GNN Swarm Detection
**Algorithm**: `GraphSAGE` (PyTorch Geometric)
By analyzing the *edges* between accounts, OSKAR identifies the mathematical signature of orchestrated bot farmsâ€”instances of Coordinated Inauthentic Behavior (CIB).

---

## ğŸ§® Mathematical Formalism

### **Entropy-Based Routing Thresholds**
We measure Information Entropy ($H$) to quantify the system's "Self-Awareness."

$$
H(p) = -\sum_{i=1}^{n} p(y_i|x) \log_2 p(y_i|x)
$$

### **Bayesian Trust Priors**
User reliability is modeled as a Beta-Bernoulli distribution updated after every verified interaction:

$$
\alpha_{\text{new}} = \alpha_{\text{old}} + \text{verified\_claims}
$$
$$
\beta_{\text{new}} = \beta_{\text{old}} + (\text{total\_claims} - \text{verified\_claims})
$$
$$
\text{Trust Score} = \frac{\alpha}{\alpha + \beta}
$$

### **GNN Aggregation (GraphSAGE)**
Neighbor feature aggregation for node $v$:

$$
h_v^k = \sigma \left( W^k \cdot \text{CONCAT} \left( h_v^{k-1}, \text{AGGREGATE}_k \left( \{h_u^{k-1}, \forall u \in \mathcal{N}(v) \} \right) \right) \right)
$$

---

## ğŸ¤– Algorithmic Engineering (IEEE-Style)

### **Core Inference Logic**

```python
# IEEE Standard Pseudo-Code for OSKAR Pipeline
Algorithm: Content_Analyze(content, social_graph)
    1: hate_logits = RoBERTa.evaluate(content)
    2: claim_mask = DeBERTa.extract_claims(content)
    
    3: if claim_mask is valid:
    4:     docs = FAISS.search(Embedding(content))
    5:     fact_verified = Neo4j.query_triples(docs)
    6:     truth_score = Fuse(docs, fact_verified)
    7: else:
    8:     truth_score = NA
    
    9: swarm_intensity = GraphSAGE.predict(social_graph)
    10: trust_prior = DB_Fetch_Trust(User_ID)
    
    11: risk_raw = Î± * hate_logits + Î² * truth_score
    12: risk_final = risk_raw * (1.0 + swarm_intensity) * (1.5 - trust_prior)
    
    13: return Map_To_Route(risk_final, Shannon_Entropy(risk_final))
```

---

## ğŸ—ï¸ Deployment Architecture

OSKAR is designed for enterprise scale, containerized with multi-stage Docker builds and Helm charts for Kubernetes.

```mermaid
graph TD
    subgraph "API Ingress"
        GW[Nginx/K8s Ingress] --> API[FastAPI Orchestrator]
    end

    subgraph "Inference Pods (GPU)"
        API --> H_POD[RoBERTa Workers]
        API --> G_POD[GNN/GraphSAGE Workers]
    end

    subgraph "Knowledge Layer"
        API --> REDIS[(Redis Caching)]
        API --> F_DB[(FAISS Vector Store)]
        F_DB --> N4J[(Neo4j Fact Graph)]
        API --> P_DB[(PostgreSQL Trust Store)]
    end
```

---

## âš¡ Performance Matrix

| Subsystem | Latency Target | Actual (CPU) | Actual (GPU) |
| :--- | :--- | :--- | :--- |
| **Hate NLP** | $\leq 120ms$ | ~90ms | **~12ms** |
| **Claim NLP** | $\leq 150ms$ | ~125ms | **~18ms** |
| **FAISS/Neo4j** | $\leq 50ms$ | ~20ms | **~2ms** |
| **GNN Inference** | $\leq 20ms$ | ~5ms | **~1ms** |
| **Total P95** | $\leq 350ms$ | ~223ms | **~36ms** |

---

## ğŸ“ Repository Structure

```text
OSKAR/
â”œâ”€â”€ MVP/
â”‚   â”œâ”€â”€ src/                    # CORE SOURCE CODE (Modular)
â”‚   â”‚   â”œâ”€â”€ api/                # FastAPI Routes & Auth
â”‚   â”‚   â”œâ”€â”€ models/             # Transformer & GNN Wrappers
â”‚   â”‚   â”œâ”€â”€ core/               # Bayesian Math & Entropy Engines
â”‚   â”‚   â””â”€â”€ infra/              # FAISS, Neo4j, Redis Drivers
â”‚   â”œâ”€â”€ tests/                  # Pytest Unit & Integration Suite
â”‚   â”œâ”€â”€ k8s/                    # Helm Charts & K8s Manifests
â”‚   â””â”€â”€ docker-compose.yml      # Local Integration Stack
â””â”€â”€ Documentation/              # Research Papers & Spec Docs
```

---

<div align="center">

### **Built for Accuracy. Deployed for Safety.**

**Developer**: Kunal | **Architecture**: Domain-Driven ML | **Mission**: Ethical AI

[Top](#ğŸ›¡ï¸-oskar-online-safety--knowledge-authenticity-resolver)

</div>
